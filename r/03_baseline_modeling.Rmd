---
title: "03_baeline_modeling"
output: html_notebook
---

## Goal

The goal of this phase is to establish a baseline predictive model using *enrollment-time* patient characteristics only. This model serves as a reference point for evaluating the predictive value of treatment assignment in later analyses.

### Modeling Question

Can we predict which patients will respond (as defined by outcomes$responder_30pct) using the attributes available at the beginning of the trial?

### Planned Attribute Sets 

#### Baseline-Only Attributes (Model 1)

- sex 
- age
- bmi
- smoker 
- comorbidity_count
- baseline_severity
- crp_mgL, alt_U_L 
- egfr_ml_min
- self_reported_adherence

#### Baseline + Treatment (Model 2)

- All baseline-only attributes 
- treatment_arm

#### Consider Later:

- site_id
- enroll_date

Because response is rare (~3%), accuracy is not a useful evaluation metric. Model performance will, instead, be assessed using metrics appropriate for imbalanced outcomes. The primary emphasis will be on precision–recall AUC. ROC–AUC and recall will be reported as secondary metrics to provide additional context on model discrimination and sensitivity. 

## Libraries Needed 

```{r}
library(caret)
library(pROC)
library(PRROC)
```

### Building Datasets for Model Generation

```{r}
set.seed(123) 

train_idx <- createDataPartition(
  baseline_df$responder_30pct,
  p = 0.8,
  list = FALSE
)

train_df <- baseline_df[train_idx, ]
test_df  <- baseline_df[-train_idx, ]
```

```{r}
prop.table(table(baseline_df$responder_30pct))
prop.table(table(train_df$responder_30pct))
prop.table(table(test_df$responder_30pct))
```

The test dataset has fewer positive, which could impact our results. We will likely see the results be a little more noisy, but I am choosing to move forward instead of resampling the dataset. This may be solvable if I did a 70/30 split instead of an 80/20 split, but I think at this point it is fine to move forward. 

I need to convert sex to a factor. The attributes responder_30pct and smoker are already 0/1 integers which will be interperted as binomials by r, so those dont need to be changed. 

```{r}
train_df$sex <- factor(train_df$sex)
test_df$sex  <- factor(test_df$sex, levels = levels(train_df$sex))
```

## Baseline Model

```{r}
model <- glm(formula = responder_30pct ~ 
               as.factor(sex) + 
               age + 
               bmi +
               smoker +
               comorbidity_count +
               baseline_severity +
               crp_mgL + 
               alt_U_L +
               egfr_ml_min +
               self_reported_adherence, 
             family=binomial(link='logit'), 
             data=train_df)
```

```{r}
summary(model)
```

A baseline-only logistic regression model was fit using t0 patient characteristics. Baseline severity showed a strong negative association with response, consistent with earlier exploratory analysis. Other baseline features did not exhibit strong independent effects in this model, potentially pointing to shared signal captured by baseline severity. Model evaluation on held-out data is used to assess predictive performance rather than coefficient significance.


```{r}
test_pred_prob <- predict(model, newdata = test_df, type = "response")
summary(test_pred_prob)
head(test_pred_prob)
```

```{r}
roc_obj <- roc(
  response = test_df$responder_30pct,
  predictor = test_pred_prob
)

auc(roc_obj)
```


```{r}
# The null PR_AUC response rate is 2.19%
mean(test_df$responder_30pct)
```

```{r}
pr_obj <- pr.curve(
  scores.class0 = test_pred_prob[test_df$responder_30pct == 1],
  scores.class1 = test_pred_prob[test_df$responder_30pct == 0],
  curve = TRUE
)

pr_obj$auc.integral
```

Despite severe outcome imbalance (~3% responders), a baseline-only logistic regression achieved a PR–AUC of 0.225 on held-out data, substantially exceeding the random baseline. This indicates strong baseline signal and supports feasibility of predictive modeling.The next step will be to redo this model with the addition of the treatment_arm attribute.

## Baseline Model + Treatment

```{r}
train_df$treatment_arm <- factor(train_df$treatment_arm)
test_df$treatment_arm  <- factor(test_df$treatment_arm, 
                                 levels = levels(train_df$treatment_arm)
                                 )
```

```{r}
levels(train_df$treatment_arm)
levels(test_df$treatment_arm)
```

```{r}
model_treatment <- glm(formula = responder_30pct ~ 
               as.factor(sex) + 
               age + 
               bmi +
               smoker +
               comorbidity_count +
               baseline_severity +
               crp_mgL + 
               alt_U_L +
               egfr_ml_min +
               self_reported_adherence +
               treatment_arm, 
             family=binomial(link='logit'), 
             data=train_df)
```

```{r}
summary(model_treatment)
```

```{r}
test_pred_prob <- predict(model_treatment, newdata = test_df, type = "response")
summary(test_pred_prob)
head(test_pred_prob)
```

```{r}
roc_obj <- roc(
  response = test_df$responder_30pct,
  predictor = test_pred_prob
)

auc(roc_obj)
```

```{r}
pr_obj <- pr.curve(
  scores.class0 = test_pred_prob[test_df$responder_30pct == 1],
  scores.class1 = test_pred_prob[test_df$responder_30pct == 0],
  curve = TRUE
)

pr_obj$auc.integral
```


In this phase, I established a baseline predictive framework using t0 characteristics only. A logistic regression model demonstrated meaningful ability to rank responders under severe class imbalance (PR–AUC ≈ 0.23). Adding treatment assignment substantially improved discrimination (ROC–AUC ≈ 0.89) but yielded only marginal gains in precision–recall performance, reflecting the rarity of response and the fact that treatment increases response probability without sharply concentrating responders. These results confirm the presence of strong baseline signal while highlighting the limits of individual-level prediction at enrollment. Subsequent analyses will focus on model simplification, robustness, and incorporation of early on-treatment information.



